{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ProductInfo:\n",
    "    \"\"\"\n",
    "    It is a class used to store the product info fetched from Flipkart.\\n\n",
    "    \"\"\"\n",
    "\n",
    "    class Review:\n",
    "        \"\"\"\n",
    "        It is a class used to store a review. It has the following attributes:\\n\n",
    "        rating - Stores the rating (Max rating is 5)\\n\n",
    "        title - Stores the title of the review in string format\\n\n",
    "        review - Stores the content of the review\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, rating: int, review_title: str, review: str) -> None:\n",
    "            self.rating: int = rating or 0\n",
    "            self.review_title: str = review_title or \"\"\n",
    "            self.review: str = review or \"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.name: str = \"\"\n",
    "        self.product_url: str = \"\"\n",
    "        self.query_url: str = \"\"\n",
    "        self.reviews: list[ProductInfo.Review] = []\n",
    "\n",
    "    def set_name(self, name: str) -> None:\n",
    "        \"\"\"\n",
    "        Sets the name of the product\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "\n",
    "    def set_query_url(self, query_url: str) -> None:\n",
    "        \"\"\"\n",
    "        Sets the query_url (URL used for fetching product info) attribute of the product\n",
    "        \"\"\"\n",
    "        self.query_url = query_url\n",
    "\n",
    "    def set_product_url(self, product_url: str) -> None:\n",
    "        \"\"\"\n",
    "        Sets the product_url (URL of the product's page) attribute of the product\n",
    "        \"\"\"\n",
    "        self.product_url = product_url\n",
    "\n",
    "    def add_review(self, rating: int, review_title: str, review: str) -> None:\n",
    "        \"\"\"\n",
    "        Adds a review in the form of a ProductInfo.Review object to reviews attribute\n",
    "        \"\"\"\n",
    "        self.reviews.append(ProductInfo.Review(rating, review_title, review))\n",
    "\n",
    "    def get_review_url(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns the reviews URL (URL of the product's reviews page)\n",
    "        \"\"\"\n",
    "        return self.product_url.replace(\"/p/\", \"/product-reviews/\")\n",
    "\n",
    "    def to_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Converts the ProductInfo Object to a Pandas DataFrame.\\n\n",
    "        Each row in the DataFrame contains:\n",
    "        - name\n",
    "        - product_url\n",
    "        - query_url\n",
    "        - review_url\n",
    "        - rating\n",
    "        - review_title\n",
    "        - review\n",
    "        \"\"\"\n",
    "        return pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"name\": self.name,\n",
    "                    \"product_url\": self.product_url,\n",
    "                    \"query_url\": self.query_url,\n",
    "                    \"review_url\": self.get_review_url(),\n",
    "                    \"rating\": self.reviews[i].rating,\n",
    "                    \"review_title\": self.reviews[i].review_title,\n",
    "                    \"review\": self.reviews[i].review,\n",
    "                }\n",
    "                for i in range(self.reviews.__len__())\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "class Flipkart:\n",
    "    WEBSITE_URL: str = \"https://www.flipkart.com/\"\n",
    "    SEARCH_API_BASEURL: str = \"https://flipkart.dvishal485.workers.dev/search/\"\n",
    "    PRODUCT_INFO_API_BASEURL: str = \"https://flipkart.dvishal485.workers.dev/product/\"\n",
    "\n",
    "    def check_connection() -> bool:\n",
    "        \"\"\"\n",
    "        Checks if Flipkart website is reachable and prints the status code\n",
    "        and returns a boolean based on the connection status.\\n\n",
    "            True - If website is reachable\\n\n",
    "            False - If website is unreachable\n",
    "        \"\"\"\n",
    "        status = urllib.request.urlopen(Flipkart.WEBSITE_URL).getcode()\n",
    "        if status >= 200 and status < 300:\n",
    "            print(f\"URL ({Flipkart.WEBSITE_URL}) is Working\\nStatus: {status}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Website is down.\\nStatus: {status}\")\n",
    "            return False\n",
    "\n",
    "    def search(param: str = \"\") -> list[ProductInfo]:\n",
    "        \"\"\"\n",
    "        A function to fetch product page URLs from flipkart based on a query parameter in string format.\\n\n",
    "        It returns a list of ProductInfo Objects containing:\\n\n",
    "            name - name of product\\n\n",
    "            product_url - URL of the product's page\\n\n",
    "            query_url - URL used for fetching product info\n",
    "        \"\"\"\n",
    "        SEARCH = lambda x: json.loads(\n",
    "            requests.get(Flipkart.SEARCH_API_BASEURL + str(x)).content\n",
    "        )[\"result\"]\n",
    "        products = []\n",
    "        for i in SEARCH(param):\n",
    "            item = ProductInfo()\n",
    "            item.set_name(i[\"name\"])\n",
    "            item.set_product_url(i[\"link\"])\n",
    "            item.set_query_url(i[\"query_url\"])\n",
    "            products.append(item)\n",
    "        return products\n",
    "\n",
    "    def get_reviews(\n",
    "        products_info: list[ProductInfo],\n",
    "        sort_order: str = \"MOST_HELPFUL\",\n",
    "        pages: int = 1,\n",
    "    ) -> list[ProductInfo]:\n",
    "        \"\"\"\n",
    "        A function to fetch reviews from a product's review page.\\n\n",
    "        It accepts a list of ProductInfo objects which must contain a valid url in product_url attribute.\\n\n",
    "        Sort Order Options:\\n\n",
    "        - MOST_HELPFUL (default)\n",
    "        - MOST_RECENT\n",
    "        - POSITIVE_FIRST\n",
    "        - NEGATIVE_FIRST\\n\n",
    "        Pages:\n",
    "            The number of review pages that need to be scraped.\n",
    "        It returns the objects after adding the reviews.\n",
    "        \"\"\"\n",
    "        for i in range(len(products_info)):\n",
    "            for p in range(1, pages + 1):\n",
    "                url = (\n",
    "                    products_info[i].get_review_url()\n",
    "                    + f\"?sortOrder={sort_order}&page={p}\"\n",
    "                )\n",
    "                try:\n",
    "                    webpage = requests.get(url)\n",
    "                    soup = BeautifulSoup(webpage.content, \"lxml\")\n",
    "                    reviews_html = soup.find(\n",
    "                        \"div\", {\"class\": \"_1YokD2 _3Mn1Gg col-9-12\"}\n",
    "                    ).find_all(\"div\", {\"class\": \"_1AtVbE col-12-12\"})\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                for id in range(len(reviews_html)):\n",
    "                    if id > 1 and id < 12:\n",
    "                        try:\n",
    "                            review = (\n",
    "                                reviews_html[id].find(\"div\", {\"class\": \"\"}).div.text\n",
    "                            )\n",
    "                            title = reviews_html[id].div.div.div.div.p.text\n",
    "                            rating = reviews_html[id].div.div.div.div.div.text\n",
    "                            products_info[i].add_review(\n",
    "                                rating=rating, review_title=title, review=review\n",
    "                            )\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error:{e}\")\n",
    "        return products_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL (https://www.flipkart.com/) is Working\n",
      "Status: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flipkart.check_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_companies = [\n",
    "    \"apple\",\n",
    "    \"ininix\",\n",
    "    \"motorola\",\n",
    "    \"nokia\",\n",
    "    \"oneplus\",\n",
    "    \"oppo\",\n",
    "    \"poco\",\n",
    "    \"realme\",\n",
    "    \"redme\",\n",
    "    \"samsung\",\n",
    "    \"vivo\",\n",
    "    \"xiaomi\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(len(phone_companies)):\n",
    "    info = Flipkart.get_reviews(Flipkart.search(phone_companies[p] + \"phone\"), pages=5)\n",
    "    df = pd.concat([i.to_df() for i in info if i != None])\n",
    "    df.to_csv(phone_companies[p] + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12713 entries, 0 to 1199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    12713 non-null  int64 \n",
      " 1   name          12713 non-null  object\n",
      " 2   product_url   12713 non-null  object\n",
      " 3   query_url     12713 non-null  object\n",
      " 4   review_url    12713 non-null  object\n",
      " 5   rating        12713 non-null  int64 \n",
      " 6   review_title  12713 non-null  object\n",
      " 7   review        12713 non-null  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 893.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([pd.read_csv(\"data/\" + i + \".csv\") for i in phone_companies])\n",
    "data = data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4680 entries, 0 to 1199\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    4680 non-null   int64 \n",
      " 1   name          4680 non-null   object\n",
      " 2   product_url   4680 non-null   object\n",
      " 3   query_url     4680 non-null   object\n",
      " 4   review_url    4680 non-null   object\n",
      " 5   rating        4680 non-null   int64 \n",
      " 6   review_title  4680 non-null   object\n",
      " 7   review        4680 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 329.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "data = data.drop([\"index\", \"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4680 entries, 0 to 4679\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   index         4680 non-null   int64 \n",
      " 1   name          4680 non-null   object\n",
      " 2   product_url   4680 non-null   object\n",
      " 3   query_url     4680 non-null   object\n",
      " 4   review_url    4680 non-null   object\n",
      " 5   rating        4680 non-null   int64 \n",
      " 6   review_title  4680 non-null   object\n",
      " 7   review        4680 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 292.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
